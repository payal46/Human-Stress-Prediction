# Human Stress Prediction

## overview
Stress is a significant concern in today's fast-paced world, affecting individuals across various demographics.Understanding the factors contributing to stress levels and predicting them accurately is crucial for effective intervention and support. In this project,we aim to analyze textual data to predict stress levels and identify factors contributing to stress.we have to read everything to know if it's positive or negative. Nowadays, technology like Natural Language Processing (NLP) in artificial intelligence makes this easier.

## Objective
1) Preprocessing and Cleaning of the data
2) Visualization on the basis of texts
3) Extracting Features from Cleaned data
4) build a text classification model using the Naive Bayes algorithm

## Dataset
https://www.kaggle.com/datasets/kreeshrajani/human-stress-prediction

## Dataset Description
This file has subreddit, post_id, sentence_range, text, label,confidence,social_timestamp
Description of columns in the file:
1) subreddit:  list of specific subreddits that users have engaged with
2) Post_id: The unique identification of the person 
3) sentence_range: : Indicates the range of sentences within the post where a particular attribute or sentiment is expressed, providing context for the associated text and label.
4) Text: The actual content or text of the post shared by users within the subreddit.
5) label:this dataset is labelled as 0 and 1, where 0 indicates no stress and 1 indicates stress.
6) confidence: Indicates the level of confidence in the range of 0 and 1.
7) social_timestamp: Denotes the timestamp when the post was shared in unix time format.

## Project Flow
Loading Packages and Data

Data Structure and Content

Missing Value Treatment

Exploratory Data Analysis

Feature Engineering

PreProcessing Data

Modeling

## About Me
I'm a Data Science enthusiast and on a quest to explore, analyze, and derive insights from data. Curious learner, avid participant in competitions, and dedicated to contributing to the data science community. Let's embark on this exciting data-driven journey together!

